{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preped\n"
     ]
    }
   ],
   "source": [
    "#Extract Data\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "datasetFile = open('./spambase.data', 'r')\n",
    "\n",
    "spam = list()\n",
    "notSpam = list()\n",
    "\n",
    "\n",
    "for line in datasetFile:\n",
    "    splitedLine = line.split(',')\n",
    "    for a in range(0, len(splitedLine)):\n",
    "        splitedLine[a] = float(splitedLine[a])\n",
    "    if(splitedLine[-1] == 1):\n",
    "        spam.append(splitedLine)\n",
    "    else:\n",
    "        notSpam.append(splitedLine)\n",
    "\n",
    "#Randomize\n",
    "random.shuffle(spam)\n",
    "random.shuffle(notSpam)\n",
    "\n",
    "training = spam\n",
    "training.extend(notSpam)\n",
    "random.shuffle(training)\n",
    "\n",
    "trainingX = list()\n",
    "trainingY = list()\n",
    "\n",
    "for row in training:\n",
    "    trainingX.append(row[:-1])\n",
    "    trainingY.append(row[-1])\n",
    "\n",
    "trainingX = np.array(trainingX)\n",
    "trainingY = np.array(trainingY)\n",
    "\n",
    "print(\"Data Preped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validation\n",
    "from sklearn import metrics \n",
    "def splitData(trainingX, trainingY, kValue):\n",
    "    amountInSection = len(trainingX)//kValue\n",
    "    leftOver = len(trainingX)%kValue\n",
    "    \n",
    "    splittedData = list()\n",
    "      \n",
    "    track = 0\n",
    "    for a in range(0, kValue):\n",
    "        toAdd = list()\n",
    "        if(leftOver > 0):\n",
    "            a = trainingX[track:(track+amountInSection+1)]\n",
    "            b = trainingY[track:(track+amountInSection+1)]\n",
    "            leftOver = leftOver - 1\n",
    "            track = track+amountInSection+1\n",
    "        else:\n",
    "            a = trainingX[track:(track+amountInSection)]\n",
    "            b = trainingY[track:(track+amountInSection)]\n",
    "            track = track+amountInSection\n",
    "        toAdd.append(a)\n",
    "        toAdd.append(b)\n",
    "        splittedData.append(toAdd)\n",
    "    return splittedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged Accuracy of Validation Set for k=5: \n",
      "0.9271901996884294\n",
      "Averaged Accuracy of Validation Set for k=10: \n",
      "0.9280595114590209\n",
      "Averaged Accuracy of Validation Set for k=20: \n",
      "0.92892527762093\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "for kFold in [5,10,20]:\n",
    "    totalAccuracy = 0\n",
    "    splittedData = splitData(trainingX, trainingY, kFold)\n",
    "\n",
    "    for a in range(0, kFold):\n",
    "        logreg = LogisticRegression()\n",
    "        trainX = list()\n",
    "        trainY = list()\n",
    "        for b in range(0, kFold):\n",
    "            if(b!=a):\n",
    "                trainX.extend(splittedData[b][0])\n",
    "                trainY.extend(splittedData[b][1])\n",
    "\n",
    "        logreg.fit(trainX, trainY)\n",
    "\n",
    "        y_pred = logreg.predict(splittedData[a][0])\n",
    "\n",
    "        confMatrix = metrics.confusion_matrix(splittedData[a][1], y_pred)\n",
    "        accuracy = (confMatrix[1][1]+confMatrix[0][0])/len(y_pred)\n",
    "        totalAccuracy = totalAccuracy + accuracy\n",
    "\n",
    "    print(\"Averaged Accuracy of Validation Set for k=%d: \" % kFold)\n",
    "    print(totalAccuracy/kFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged Accuracy of Validation Set for k=5: \n",
      "0.8880699145541235\n",
      "Averaged Accuracy of Validation Set for k=10: \n",
      "0.8863335848344807\n",
      "Averaged Accuracy of Validation Set for k=20: \n",
      "0.8861142480707699\n"
     ]
    }
   ],
   "source": [
    "LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "for kFold in [5,10,20]:\n",
    "    totalAccuracy = 0\n",
    "    splittedData = splitData(trainingX, trainingY, kFold)\n",
    "\n",
    "    for a in range(0, kFold):\n",
    "        trainX = list()\n",
    "        trainY = list()\n",
    "        for b in range(0, kFold):\n",
    "            if(b!=a):\n",
    "                trainX.extend(splittedData[b][0])\n",
    "                trainY.extend(splittedData[b][1])\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        lda.fit(trainX, trainY)\n",
    "        \n",
    "        y_pred = lda.predict(splittedData[a][0])\n",
    "\n",
    "        confMatrix = metrics.confusion_matrix(splittedData[a][1], y_pred)\n",
    "        accuracy = (confMatrix[1][1]+confMatrix[0][0])/len(y_pred)\n",
    "        totalAccuracy = totalAccuracy + accuracy\n",
    "\n",
    "    print(\"Averaged Accuracy of Validation Set for k=%d: \" % kFold)\n",
    "    print(totalAccuracy/kFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
